{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment lab 05\n",
    "- 19.04.21\n",
    "\n",
    "## Master Class: Machine Learning (5MI2018)\n",
    "- Faculty of Economic Science\n",
    "- University of Neuchatel (Switzerland)\n",
    "- Lab 5, see ML21_Exercise_5.pdf for more information\n",
    "\n",
    "## Authors: \n",
    "- Romain Claret @RomainClaret\n",
    "- Sylvain Robert-Nicoud @Nic0uds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features names and the values of the categories from adult.names (build a dictionary)\n",
    "\n",
    "data_dict = {}\n",
    "with open('adult.names') as f:\n",
    "    for l in f:\n",
    "        if l[0] == '|' or ':' not in l: continue\n",
    "        c = l.split(':')\n",
    "        if c[1].startswith(' continuous'): data_dict[c[0]] = \"\"\n",
    "        else: data_dict[c[0]] = c[1].replace(\"\\n\",\"\").replace(\".\",\"\").replace(\" \",\"\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py:767: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return read_csv(**locals())\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py:767: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return read_csv(**locals())\n"
     ]
    }
   ],
   "source": [
    "# in the specifications (adult.names): Unknown values are replaced with the character '?'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "header = list(data_dict.keys())+['income']\n",
    "df_train = pd.read_table(\"adult.data\", sep=r',\\s', na_values='?', header=None, names=header).dropna()\n",
    "df_evaluate = pd.read_table(\"adult.test\", sep=r',\\s', na_values='?', skiprows=[0], header=None, names=header).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas_profiling\n",
    "#df_train.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_evaluate.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping the education because it's redundant with education-num\n",
    "# droping the occupation because it's not generic enough, we have much more categories that those captured in the training sample\n",
    "# droping the relationship because it's not generic enough, we have much more categories that those captured in the training sample\n",
    "\n",
    "drop_list = [\"education\", \"occupation\", \"relationship\"]\n",
    "df_train = df_train.drop(columns=drop_list)\n",
    "df_evaluate = df_evaluate.drop(columns=drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing categories with multiple options into lower dimensions classification (into binary preferably) when possible\n",
    "# - marital-status could be reduced as Married or Not-Married\n",
    "# marital-status ['Never-married' 'Married-civ-spouse' 'Divorced' 'Married-spouse-absent' 'Separated' 'Married-AF-spouse' 'Widowed']\n",
    "# - workclass could be recuded to 3 dimensions: Government, Private, and Self-Employment\n",
    "# Note that we take into consideration all the options for the category from the specifications\n",
    "# ['State-gov' 'Self-emp-not-inc' 'Private' 'Federal-gov' 'Local-gov' 'Self-emp-inc' 'Without-pay']\n",
    "\n",
    "dict_replace = {\n",
    "    'marital-status' : {\n",
    "        'Never-married': 'Not-Married',\n",
    "        'Married-civ-spouse': 'Married',\n",
    "        'Divorced': 'Not-Married',\n",
    "        'Married-spouse-absent': 'Married',\n",
    "        'Separated': 'Married',\n",
    "        'Married-AF-spouse': 'Married',\n",
    "        'Widowed': 'Not-Married'\n",
    "        },\n",
    "    'workclass': {\n",
    "        'State-gov': 'Government',\n",
    "        'Self-emp-not-inc': 'Self-Employment',\n",
    "        'Federal-gov': 'Government',\n",
    "        'Local-gov': 'Government',\n",
    "        'Self-emp-inc': 'Self-Employment'\n",
    "        }\n",
    "}\n",
    "\n",
    "df_train.replace(dict_replace, inplace=True)\n",
    "df_evaluate.replace(dict_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniformizing the categories between the training and evaluation datasets\n",
    "# indeed, there is a . at the end of the value in the evaluation dataset for the income category and not in the training dataset\n",
    "df_evaluate[\"income\"].replace({\"<=50K.\": \"<=50K\", \">50K.\": \">50K\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# for binary categories we will be using a label encoder\n",
    "# - marital-status, sex, income\n",
    "\n",
    "for l in [\"marital-status\", \"sex\", \"income\"]:\n",
    "    l_enc = LabelEncoder()\n",
    "    encoder_train = l_enc.fit(df_train[l])\n",
    "    encoder_evaluate = l_enc.fit(df_evaluate[l])\n",
    "    df_train[\"encoded_\"+l] = encoder_train.transform(df_train[l])\n",
    "    df_evaluate[\"encoded_\"+l] = encoder_evaluate.transform(df_evaluate[l])\n",
    "    \n",
    "#df_train.reset_index(inplace=True,drop=True)\n",
    "#df_evaluate.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For non-binary categories, first we check the specifications of the dataset to validate all the options per category (we have data_dict)\n",
    "# Indeed, the values in the categories are not always all present in a dataset\n",
    "# race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "# native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "# and our custom category: workclass: Government, Private, and Self-Employment\n",
    "# adding temporary fake data for the one hot encoder\n",
    "\n",
    "fake_row = df_train[:1].copy()\n",
    "df_fake = pd.DataFrame(data=fake_row, columns=df_train.columns)\n",
    "\n",
    "cats_nonbinary = [\"race\", \"native-country\"]\n",
    "\n",
    "for c in cats_nonbinary:\n",
    "    for v in data_dict[c]:\n",
    "        fake_row[c] = v\n",
    "        df_fake = df_fake.append(fake_row, ignore_index=True)\n",
    "        \n",
    "cat_workclass = [\"Government\", \"Private\", \"Self-Employment\"]\n",
    "for cw in cat_workclass:\n",
    "    fake_row[\"workclass\"] = cw\n",
    "    df_fake = df_fake.append(fake_row, ignore_index=True)\n",
    "    \n",
    "df_train = df_train.append(df_fake).reset_index(drop=True)\n",
    "df_evaluate = df_evaluate.append(df_fake).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get meaningful columns\n",
    "continuous_features = [k for k, v in data_dict.items() if v == \"\"]\n",
    "unencoded_features = [\"workclass\", \"race\", \"native-country\"]\n",
    "encoded_features = [c for c in df_train if c.startswith('encoded')]\n",
    "columns = continuous_features+unencoded_features+encoded_features\n",
    "#columns.remove(\"encoded_income\")\n",
    "#columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Standardizing of numeric values\n",
    "# Doesn't have a lot of meaning in the case of decision trees as it's not using distances (like KNN)\n",
    "# But it's just a pedagological flavor and to use the ColumnTranformer for whatever reason \n",
    "# https://stats.stackexchange.com/questions/10289/whats-the-difference-between-normalization-and-standardization\n",
    "\n",
    "# for non-binary categories we will be using a onehot encoder as decision trees are sensitive to leaves values\n",
    "\n",
    "# We choose a the best parameters from lab2 for the decision tree\n",
    "# depth=8 Train accuracy_score 0.8550292179535\n",
    "# depth=8 Test accuracy_score 0.8465108569534229\n",
    "# depth=8 Evaluation accuracy_score 0.8469455511288181 \n",
    "\n",
    "feature_transformation = ColumnTransformer(transformers=[\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), unencoded_features+encoded_features[:-1]),\n",
    "    ('numerical', StandardScaler(), continuous_features)\n",
    "])\n",
    "\n",
    "adult_pipeline = Pipeline(steps=[\n",
    "  ('features', feature_transformation),\n",
    "  ('classifier', DecisionTreeClassifier(criterion='gini', random_state=1, max_depth=8))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('categorical',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['workclass', 'race', 'native-country',\n",
       "                                  'encoded_marital-status', 'encoded_sex']),\n",
       "                                ('numerical', StandardScaler(),\n",
       "                                 ['age', 'fnlwgt', 'education-num',\n",
       "                                  'capital-gain', 'capital-loss',\n",
       "                                  'hours-per-week'])])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifiers={\n",
    "#    'Dtree':DecisionTreeClassifier(random_state=42)\n",
    "#}\n",
    "#grids={\n",
    "#    'Dtree':{\n",
    "#        #'classifier__criterion':['gini', 'entropy'],\n",
    "#        'classifier__max_depth': range(7, 8),\n",
    "#        #'classifier__ccp_alpha': [x * 0.1 for x in range(0, 10)],\n",
    "#        #'classifier__min_samples_split': [x * 0.1 for x in range(1, 10)],\n",
    "#        #'classifier__min_samples_leaf': range(1, 8),\n",
    "#        #'classifier__min_weight_fraction_leaf': [x * 0.1 for x in range(1, 5)],\n",
    "#        #'classifier__min_impurity_decrease': range(1, 8)\n",
    "#    }\n",
    "#}\n",
    "#for c in list(classifiers.keys()):\n",
    "#    clf = classifiers[c]\n",
    "#    grid = grids[c]\n",
    "#    adult_pipeline.set_params(classifier=clf)\n",
    "#    gridSearch_model = GridSearchCV(adult_pipeline, grid, )\n",
    "#    gridSearch_model.fit(df_train, df_train[\"encoded_income\"])\n",
    "#    print(gridSearch_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Time elapsed 69.29844117164612\n",
      "{'classifier': DecisionTreeClassifier(min_samples_leaf=36, random_state=1), 'classifier__min_samples_leaf': 36}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "#set workers\n",
    "nb_workers = mp.cpu_count()-1\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "#https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n",
    "grids_params = [\n",
    "    {\n",
    "        'classifier': (DecisionTreeClassifier(random_state=1),),\n",
    "        'classifier__criterion':['gini', 'entropy'], #best_solo='entropy'\n",
    "        'classifier__max_depth': range(8, 12), #best_solo=8\n",
    "        #'classifier__ccp_alpha': [x * 0.1 for x in range(0, 1)], #default: 0.0 #best_solo=0.0\n",
    "        'classifier__min_samples_split': range(2,10), #default: 2 #best_solo=11\n",
    "        #'classifier__min_samples_leaf': range(1, 3), #default: 1 #best_solo=34\n",
    "        #'classifier__min_weight_fraction_leaf': [x * 0.1 for x in range(0, 2)], #default: 0.0 #best_solo=0.1\n",
    "        #'classifier__min_impurity_decrease': range(0, 1), #default: 0 #best_solo=0\n",
    "        'classifier__max_features': range(25,31) #default: n_features = 11 #best_solo=4\n",
    "    }#,\n",
    "    #{\n",
    "    #    'classifier': (KNeighborsClassifier(),),\n",
    "    #    'classifier__n_neighbors': range(25, 26),\n",
    "    #}\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "grid_search_model = GridSearchCV(estimator=adult_pipeline, param_grid=grids_params, n_jobs=25, cv=10, verbose=10)\n",
    "grid_search_model.fit(df_train, df_train[\"encoded_income\"])\n",
    "end = time.time()\n",
    "print(\"Time elapsed\",str(end - start))\n",
    "print(grid_search_model.best_params_)\n",
    "#print(grid_search_model.cv_results_)\n",
    "#print(grid_search_model.refit_time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>param_classifier__min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.588173</td>\n",
       "      <td>0.811497</td>\n",
       "      <td>0.152540</td>\n",
       "      <td>0.063191</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>20</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.830907</td>\n",
       "      <td>0.838187</td>\n",
       "      <td>0.834161</td>\n",
       "      <td>0.823568</td>\n",
       "      <td>0.832837</td>\n",
       "      <td>0.840450</td>\n",
       "      <td>0.838795</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.843098</td>\n",
       "      <td>0.841774</td>\n",
       "      <td>0.837283</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.070602</td>\n",
       "      <td>0.728922</td>\n",
       "      <td>0.199287</td>\n",
       "      <td>0.084219</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>21</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.831899</td>\n",
       "      <td>0.841496</td>\n",
       "      <td>0.839788</td>\n",
       "      <td>0.819927</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.842436</td>\n",
       "      <td>0.840119</td>\n",
       "      <td>0.847071</td>\n",
       "      <td>0.842436</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.838376</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.953925</td>\n",
       "      <td>0.483752</td>\n",
       "      <td>0.218796</td>\n",
       "      <td>0.057092</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>22</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.831899</td>\n",
       "      <td>0.843150</td>\n",
       "      <td>0.839788</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.838795</td>\n",
       "      <td>0.844091</td>\n",
       "      <td>0.838133</td>\n",
       "      <td>0.848726</td>\n",
       "      <td>0.843760</td>\n",
       "      <td>0.839126</td>\n",
       "      <td>0.838872</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.861185</td>\n",
       "      <td>0.907171</td>\n",
       "      <td>0.161396</td>\n",
       "      <td>0.088079</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>23</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.833885</td>\n",
       "      <td>0.840503</td>\n",
       "      <td>0.842767</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.841443</td>\n",
       "      <td>0.844422</td>\n",
       "      <td>0.839457</td>\n",
       "      <td>0.848064</td>\n",
       "      <td>0.845084</td>\n",
       "      <td>0.839788</td>\n",
       "      <td>0.839667</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.103444</td>\n",
       "      <td>1.423095</td>\n",
       "      <td>0.157354</td>\n",
       "      <td>0.046475</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>24</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.838187</td>\n",
       "      <td>0.841165</td>\n",
       "      <td>0.846077</td>\n",
       "      <td>0.819927</td>\n",
       "      <td>0.840119</td>\n",
       "      <td>0.844422</td>\n",
       "      <td>0.840781</td>\n",
       "      <td>0.844422</td>\n",
       "      <td>0.846408</td>\n",
       "      <td>0.840450</td>\n",
       "      <td>0.840196</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.321752</td>\n",
       "      <td>0.732788</td>\n",
       "      <td>0.210370</td>\n",
       "      <td>0.079732</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>25</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.836863</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.843429</td>\n",
       "      <td>0.822906</td>\n",
       "      <td>0.837471</td>\n",
       "      <td>0.844422</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.848064</td>\n",
       "      <td>0.842436</td>\n",
       "      <td>0.840494</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.138505</td>\n",
       "      <td>0.654658</td>\n",
       "      <td>0.143364</td>\n",
       "      <td>0.071879</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>26</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.836532</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.845084</td>\n",
       "      <td>0.825554</td>\n",
       "      <td>0.839126</td>\n",
       "      <td>0.843760</td>\n",
       "      <td>0.838795</td>\n",
       "      <td>0.855677</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.839126</td>\n",
       "      <td>0.841454</td>\n",
       "      <td>0.007574</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.342891</td>\n",
       "      <td>0.731975</td>\n",
       "      <td>0.190388</td>\n",
       "      <td>0.067392</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>27</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.839841</td>\n",
       "      <td>0.840172</td>\n",
       "      <td>0.846077</td>\n",
       "      <td>0.825554</td>\n",
       "      <td>0.840119</td>\n",
       "      <td>0.844091</td>\n",
       "      <td>0.839788</td>\n",
       "      <td>0.853691</td>\n",
       "      <td>0.847733</td>\n",
       "      <td>0.840450</td>\n",
       "      <td>0.841752</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.927128</td>\n",
       "      <td>0.709583</td>\n",
       "      <td>0.170758</td>\n",
       "      <td>0.060087</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>28</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.837194</td>\n",
       "      <td>0.841165</td>\n",
       "      <td>0.845746</td>\n",
       "      <td>0.825223</td>\n",
       "      <td>0.840450</td>\n",
       "      <td>0.844091</td>\n",
       "      <td>0.837471</td>\n",
       "      <td>0.855677</td>\n",
       "      <td>0.844753</td>\n",
       "      <td>0.840781</td>\n",
       "      <td>0.841255</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.131379</td>\n",
       "      <td>0.253832</td>\n",
       "      <td>0.181050</td>\n",
       "      <td>0.054463</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>29</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.836532</td>\n",
       "      <td>0.840172</td>\n",
       "      <td>0.844091</td>\n",
       "      <td>0.826216</td>\n",
       "      <td>0.840781</td>\n",
       "      <td>0.844753</td>\n",
       "      <td>0.838795</td>\n",
       "      <td>0.857001</td>\n",
       "      <td>0.847733</td>\n",
       "      <td>0.840781</td>\n",
       "      <td>0.841686</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.981728</td>\n",
       "      <td>1.202344</td>\n",
       "      <td>0.149800</td>\n",
       "      <td>0.060495</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>30</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.834878</td>\n",
       "      <td>0.840834</td>\n",
       "      <td>0.848395</td>\n",
       "      <td>0.829196</td>\n",
       "      <td>0.840119</td>\n",
       "      <td>0.846408</td>\n",
       "      <td>0.839126</td>\n",
       "      <td>0.857994</td>\n",
       "      <td>0.848064</td>\n",
       "      <td>0.840450</td>\n",
       "      <td>0.842546</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.299082</td>\n",
       "      <td>1.648126</td>\n",
       "      <td>0.168121</td>\n",
       "      <td>0.083342</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>31</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.833223</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.845415</td>\n",
       "      <td>0.832837</td>\n",
       "      <td>0.837471</td>\n",
       "      <td>0.847071</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.858656</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.839788</td>\n",
       "      <td>0.842381</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.422746</td>\n",
       "      <td>0.563099</td>\n",
       "      <td>0.176984</td>\n",
       "      <td>0.032819</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>32</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.835870</td>\n",
       "      <td>0.840834</td>\n",
       "      <td>0.846077</td>\n",
       "      <td>0.833168</td>\n",
       "      <td>0.838133</td>\n",
       "      <td>0.844422</td>\n",
       "      <td>0.837140</td>\n",
       "      <td>0.856670</td>\n",
       "      <td>0.848726</td>\n",
       "      <td>0.840450</td>\n",
       "      <td>0.842149</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.167041</td>\n",
       "      <td>0.742845</td>\n",
       "      <td>0.183249</td>\n",
       "      <td>0.065275</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>33</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.835208</td>\n",
       "      <td>0.838848</td>\n",
       "      <td>0.845746</td>\n",
       "      <td>0.834161</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.845746</td>\n",
       "      <td>0.835816</td>\n",
       "      <td>0.854353</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>0.841112</td>\n",
       "      <td>0.842282</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.318435</td>\n",
       "      <td>0.442153</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.059658</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>34</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.836863</td>\n",
       "      <td>0.838187</td>\n",
       "      <td>0.844091</td>\n",
       "      <td>0.837140</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.844753</td>\n",
       "      <td>0.836809</td>\n",
       "      <td>0.856008</td>\n",
       "      <td>0.852698</td>\n",
       "      <td>0.840450</td>\n",
       "      <td>0.842546</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.091913</td>\n",
       "      <td>0.832141</td>\n",
       "      <td>0.198254</td>\n",
       "      <td>0.072480</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>35</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.834547</td>\n",
       "      <td>0.837856</td>\n",
       "      <td>0.845746</td>\n",
       "      <td>0.836147</td>\n",
       "      <td>0.836809</td>\n",
       "      <td>0.841443</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.852036</td>\n",
       "      <td>0.852367</td>\n",
       "      <td>0.840119</td>\n",
       "      <td>0.841553</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.031414</td>\n",
       "      <td>0.396793</td>\n",
       "      <td>0.208651</td>\n",
       "      <td>0.048641</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>36</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.834878</td>\n",
       "      <td>0.835870</td>\n",
       "      <td>0.847402</td>\n",
       "      <td>0.835816</td>\n",
       "      <td>0.836809</td>\n",
       "      <td>0.843098</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.850050</td>\n",
       "      <td>0.856008</td>\n",
       "      <td>0.839126</td>\n",
       "      <td>0.841752</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.707274</td>\n",
       "      <td>1.475320</td>\n",
       "      <td>0.147319</td>\n",
       "      <td>0.075624</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>37</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.835208</td>\n",
       "      <td>0.836863</td>\n",
       "      <td>0.846077</td>\n",
       "      <td>0.835154</td>\n",
       "      <td>0.836147</td>\n",
       "      <td>0.841112</td>\n",
       "      <td>0.838795</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.854022</td>\n",
       "      <td>0.835485</td>\n",
       "      <td>0.840792</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.800970</td>\n",
       "      <td>1.289882</td>\n",
       "      <td>0.151157</td>\n",
       "      <td>0.073760</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>38</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.836201</td>\n",
       "      <td>0.833554</td>\n",
       "      <td>0.846077</td>\n",
       "      <td>0.836147</td>\n",
       "      <td>0.836809</td>\n",
       "      <td>0.841112</td>\n",
       "      <td>0.841774</td>\n",
       "      <td>0.848395</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>0.834823</td>\n",
       "      <td>0.840825</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.238042</td>\n",
       "      <td>1.623381</td>\n",
       "      <td>0.177583</td>\n",
       "      <td>0.104436</td>\n",
       "      <td>DecisionTreeClassifier(min_samples_leaf=34, ra...</td>\n",
       "      <td>39</td>\n",
       "      <td>{'classifier': DecisionTreeClassifier(min_samp...</td>\n",
       "      <td>0.838848</td>\n",
       "      <td>0.836201</td>\n",
       "      <td>0.846077</td>\n",
       "      <td>0.837471</td>\n",
       "      <td>0.837471</td>\n",
       "      <td>0.840781</td>\n",
       "      <td>0.842436</td>\n",
       "      <td>0.849719</td>\n",
       "      <td>0.853029</td>\n",
       "      <td>0.833499</td>\n",
       "      <td>0.841553</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        8.588173      0.811497         0.152540        0.063191   \n",
       "1        9.070602      0.728922         0.199287        0.084219   \n",
       "2        9.953925      0.483752         0.218796        0.057092   \n",
       "3        7.861185      0.907171         0.161396        0.088079   \n",
       "4        7.103444      1.423095         0.157354        0.046475   \n",
       "5        8.321752      0.732788         0.210370        0.079732   \n",
       "6        9.138505      0.654658         0.143364        0.071879   \n",
       "7        8.342891      0.731975         0.190388        0.067392   \n",
       "8        8.927128      0.709583         0.170758        0.060087   \n",
       "9        9.131379      0.253832         0.181050        0.054463   \n",
       "10       6.981728      1.202344         0.149800        0.060495   \n",
       "11       7.299082      1.648126         0.168121        0.083342   \n",
       "12       7.422746      0.563099         0.176984        0.032819   \n",
       "13       8.167041      0.742845         0.183249        0.065275   \n",
       "14       8.318435      0.442153         0.142610        0.059658   \n",
       "15       8.091913      0.832141         0.198254        0.072480   \n",
       "16       9.031414      0.396793         0.208651        0.048641   \n",
       "17       7.707274      1.475320         0.147319        0.075624   \n",
       "18       6.800970      1.289882         0.151157        0.073760   \n",
       "19       7.238042      1.623381         0.177583        0.104436   \n",
       "\n",
       "                                     param_classifier  \\\n",
       "0   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "1   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "2   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "3   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "4   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "5   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "6   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "7   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "8   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "9   DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "10  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "11  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "12  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "13  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "14  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "15  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "16  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "17  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "18  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "19  DecisionTreeClassifier(min_samples_leaf=34, ra...   \n",
       "\n",
       "   param_classifier__min_samples_leaf  \\\n",
       "0                                  20   \n",
       "1                                  21   \n",
       "2                                  22   \n",
       "3                                  23   \n",
       "4                                  24   \n",
       "5                                  25   \n",
       "6                                  26   \n",
       "7                                  27   \n",
       "8                                  28   \n",
       "9                                  29   \n",
       "10                                 30   \n",
       "11                                 31   \n",
       "12                                 32   \n",
       "13                                 33   \n",
       "14                                 34   \n",
       "15                                 35   \n",
       "16                                 36   \n",
       "17                                 37   \n",
       "18                                 38   \n",
       "19                                 39   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classifier': DecisionTreeClassifier(min_samp...           0.830907   \n",
       "1   {'classifier': DecisionTreeClassifier(min_samp...           0.831899   \n",
       "2   {'classifier': DecisionTreeClassifier(min_samp...           0.831899   \n",
       "3   {'classifier': DecisionTreeClassifier(min_samp...           0.833885   \n",
       "4   {'classifier': DecisionTreeClassifier(min_samp...           0.838187   \n",
       "5   {'classifier': DecisionTreeClassifier(min_samp...           0.836863   \n",
       "6   {'classifier': DecisionTreeClassifier(min_samp...           0.836532   \n",
       "7   {'classifier': DecisionTreeClassifier(min_samp...           0.839841   \n",
       "8   {'classifier': DecisionTreeClassifier(min_samp...           0.837194   \n",
       "9   {'classifier': DecisionTreeClassifier(min_samp...           0.836532   \n",
       "10  {'classifier': DecisionTreeClassifier(min_samp...           0.834878   \n",
       "11  {'classifier': DecisionTreeClassifier(min_samp...           0.833223   \n",
       "12  {'classifier': DecisionTreeClassifier(min_samp...           0.835870   \n",
       "13  {'classifier': DecisionTreeClassifier(min_samp...           0.835208   \n",
       "14  {'classifier': DecisionTreeClassifier(min_samp...           0.836863   \n",
       "15  {'classifier': DecisionTreeClassifier(min_samp...           0.834547   \n",
       "16  {'classifier': DecisionTreeClassifier(min_samp...           0.834878   \n",
       "17  {'classifier': DecisionTreeClassifier(min_samp...           0.835208   \n",
       "18  {'classifier': DecisionTreeClassifier(min_samp...           0.836201   \n",
       "19  {'classifier': DecisionTreeClassifier(min_samp...           0.838848   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.838187           0.834161           0.823568   \n",
       "1            0.841496           0.839788           0.819927   \n",
       "2            0.843150           0.839788           0.821251   \n",
       "3            0.840503           0.842767           0.821251   \n",
       "4            0.841165           0.846077           0.819927   \n",
       "5            0.841827           0.843429           0.822906   \n",
       "6            0.841827           0.845084           0.825554   \n",
       "7            0.840172           0.846077           0.825554   \n",
       "8            0.841165           0.845746           0.825223   \n",
       "9            0.840172           0.844091           0.826216   \n",
       "10           0.840834           0.848395           0.829196   \n",
       "11           0.841827           0.845415           0.832837   \n",
       "12           0.840834           0.846077           0.833168   \n",
       "13           0.838848           0.845746           0.834161   \n",
       "14           0.838187           0.844091           0.837140   \n",
       "15           0.837856           0.845746           0.836147   \n",
       "16           0.835870           0.847402           0.835816   \n",
       "17           0.836863           0.846077           0.835154   \n",
       "18           0.833554           0.846077           0.836147   \n",
       "19           0.836201           0.846077           0.837471   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.832837           0.840450           0.838795   \n",
       "1            0.836478           0.842436           0.840119   \n",
       "2            0.838795           0.844091           0.838133   \n",
       "3            0.841443           0.844422           0.839457   \n",
       "4            0.840119           0.844422           0.840781   \n",
       "5            0.837471           0.844422           0.838464   \n",
       "6            0.839126           0.843760           0.838795   \n",
       "7            0.840119           0.844091           0.839788   \n",
       "8            0.840450           0.844091           0.837471   \n",
       "9            0.840781           0.844753           0.838795   \n",
       "10           0.840119           0.846408           0.839126   \n",
       "11           0.837471           0.847071           0.838464   \n",
       "12           0.838133           0.844422           0.837140   \n",
       "13           0.838464           0.845746           0.835816   \n",
       "14           0.838464           0.844753           0.836809   \n",
       "15           0.836809           0.841443           0.838464   \n",
       "16           0.836809           0.843098           0.838464   \n",
       "17           0.836147           0.841112           0.838795   \n",
       "18           0.836809           0.841112           0.841774   \n",
       "19           0.837471           0.840781           0.842436   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.849057           0.843098           0.841774         0.837283   \n",
       "1            0.847071           0.842436           0.842105         0.838376   \n",
       "2            0.848726           0.843760           0.839126         0.838872   \n",
       "3            0.848064           0.845084           0.839788         0.839667   \n",
       "4            0.844422           0.846408           0.840450         0.840196   \n",
       "5            0.849057           0.848064           0.842436         0.840494   \n",
       "6            0.855677           0.849057           0.839126         0.841454   \n",
       "7            0.853691           0.847733           0.840450         0.841752   \n",
       "8            0.855677           0.844753           0.840781         0.841255   \n",
       "9            0.857001           0.847733           0.840781         0.841686   \n",
       "10           0.857994           0.848064           0.840450         0.842546   \n",
       "11           0.858656           0.849057           0.839788         0.842381   \n",
       "12           0.856670           0.848726           0.840450         0.842149   \n",
       "13           0.854353           0.853360           0.841112         0.842282   \n",
       "14           0.856008           0.852698           0.840450         0.842546   \n",
       "15           0.852036           0.852367           0.840119         0.841553   \n",
       "16           0.850050           0.856008           0.839126         0.841752   \n",
       "17           0.849057           0.854022           0.835485         0.840792   \n",
       "18           0.848395           0.853360           0.834823         0.840825   \n",
       "19           0.849719           0.853029           0.833499         0.841553   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.006812               20  \n",
       "1         0.007233               19  \n",
       "2         0.007260               18  \n",
       "3         0.007131               17  \n",
       "4         0.007247               16  \n",
       "5         0.007043               15  \n",
       "6         0.007574               11  \n",
       "7         0.006923                7  \n",
       "8         0.007329               12  \n",
       "9         0.007513                8  \n",
       "10        0.007617                2  \n",
       "11        0.007497                3  \n",
       "12        0.006638                5  \n",
       "13        0.006913                4  \n",
       "14        0.006527                1  \n",
       "15        0.006087                9  \n",
       "16        0.006819                6  \n",
       "17        0.006352               14  \n",
       "18        0.006255               13  \n",
       "19        0.005953               10  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the fake rows\n",
    "df_train = df_train[:-len(df_fake)]\n",
    "df_evaluate = df_evaluate[:-len(df_fake)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# make training and testings sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train,df_train[\"encoded_income\"],test_size=0.2,random_state=1)\n",
    "\n",
    "# make evaluation sets\n",
    "X_evaluate = df_evaluate\n",
    "y_evaluate = df_evaluate[\"encoded_income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy_score 0.8610385842761822\n",
      "Test accuracy_score 0.8604342781369136\n",
      "Evaluation accuracy_score 0.8400398406374502 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#present depth with best score for evaluation dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_hat_dtree_train = grid_search_model.predict(X_train)\n",
    "y_hat_dtree_test = grid_search_model.predict(X_test)\n",
    "y_hat_dtree_evaluate = grid_search_model.predict(X_evaluate)\n",
    "\n",
    "print(\"Train accuracy_score\",accuracy_score(y_train,y_hat_dtree_train))\n",
    "print(\"Test accuracy_score\",accuracy_score(y_test,y_hat_dtree_test))\n",
    "print(\"Evaluation accuracy_score\",accuracy_score(y_evaluate,y_hat_dtree_evaluate),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab 03 results:\n",
    "# depth=8 Train accuracy_score 0.8539931203116582\n",
    "# depth=8 Test accuracy_score 0.8518150174042765\n",
    "# depth=8 Evaluation accuracy_score 0.8470783532536521 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(grid_search_model, open(\"grid_search_model.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handler = open(filename, 'r').readlines()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'adult.test'\n",
    "file_handler = open(filename, 'r').readlines()[1:]\n",
    "prefix_file = \"adult_2021_cw_\"\n",
    "week_number = 1\n",
    "split_into = 10\n",
    "line_count = 0\n",
    "file_length = len(file_handler)\n",
    "\n",
    "for i in range(0,file_length):\n",
    "    if i % ((file_length)//split_into) == 0 and i+((file_length//split_into)//2) < file_length:\n",
    "        open(str(prefix_file)+str(week_number) + \".csv\", \"w+\").writelines(file_handler[i:i+(file_length//split_into)])\n",
    "        week_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pipeline_model = pickle.load( open(\"grid_search_model.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult_2021_cw_1.csv accuracy_score: 0.8381079280479681 \n",
      "\n",
      "adult_2021_cw_2.csv accuracy_score: 0.8430851063829787 \n",
      "\n",
      "adult_2021_cw_3.csv accuracy_score: 0.8458471760797343 \n",
      "\n",
      "adult_2021_cw_4.csv accuracy_score: 0.8304405874499332 \n",
      "\n",
      "adult_2021_cw_5.csv accuracy_score: 0.8373015873015873 \n",
      "\n",
      "adult_2021_cw_6.csv accuracy_score: 0.836241610738255 \n",
      "\n",
      "adult_2021_cw_7.csv accuracy_score: 0.8545335942596216 \n",
      "\n",
      "adult_2021_cw_8.csv accuracy_score: 0.83994708994709 \n",
      "\n",
      "adult_2021_cw_9.csv accuracy_score: 0.8317757009345794 \n",
      "\n",
      "adult_2021_cw_10.csv accuracy_score: 0.843687374749499 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "weeks_count = 10\n",
    "filename = 'adult.test'\n",
    "prefix_file = \"adult_2021_cw_\"\n",
    "\n",
    "# get the features names and the values of the categories from adult.names (build a dictionary)\n",
    "\n",
    "data_dict = {}\n",
    "with open('adult.names') as f:\n",
    "    for l in f:\n",
    "        if l[0] == '|' or ':' not in l: continue\n",
    "        c = l.split(':')\n",
    "        if c[1].startswith(' continuous'): data_dict[c[0]] = \"\"\n",
    "        else: data_dict[c[0]] = c[1].replace(\"\\n\",\"\").replace(\".\",\"\").replace(\" \",\"\").split(\",\")\n",
    "            \n",
    "header = list(data_dict.keys())+['income']\n",
    "            \n",
    "for i in range (weeks_count):\n",
    "    filename = str(prefix_file)+str(i+1)+\".csv\"\n",
    "    df_weekly = pd.read_table(filename, sep=r',\\s', na_values='?', skiprows=[0], header=None, names=header).dropna()\n",
    "    \n",
    "    drop_list = [\"education\", \"occupation\", \"relationship\"]\n",
    "    df_weekly = df_weekly.drop(columns=drop_list)\n",
    "    \n",
    "    dict_replace = {\n",
    "    'marital-status' : {\n",
    "        'Never-married': 'Not-Married',\n",
    "        'Married-civ-spouse': 'Married',\n",
    "        'Divorced': 'Not-Married',\n",
    "        'Married-spouse-absent': 'Married',\n",
    "        'Separated': 'Married',\n",
    "        'Married-AF-spouse': 'Married',\n",
    "        'Widowed': 'Not-Married'\n",
    "        },\n",
    "    'workclass': {\n",
    "        'State-gov': 'Government',\n",
    "        'Self-emp-not-inc': 'Self-Employment',\n",
    "        'Federal-gov': 'Government',\n",
    "        'Local-gov': 'Government',\n",
    "        'Self-emp-inc': 'Self-Employment'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    df_weekly.replace(dict_replace, inplace=True)\n",
    "    \n",
    "    df_weekly[\"income\"].replace({\"<=50K.\": \"<=50K\", \">50K.\": \">50K\"}, inplace=True)\n",
    "    \n",
    "    for l in [\"marital-status\", \"sex\", \"income\"]:\n",
    "        l_enc = LabelEncoder()\n",
    "        encoder_weekly = l_enc.fit(df_weekly[l])\n",
    "        df_weekly[\"encoded_\"+l] = encoder_weekly.transform(df_weekly[l])\n",
    "    \n",
    "    y_hat_dtree_weekly = pipeline_model.predict(df_weekly)\n",
    "\n",
    "    print(filename, \"accuracy_score:\",accuracy_score(df_weekly[\"encoded_income\"],y_hat_dtree_weekly),\"\\n\")\n",
    "    \n",
    "    pd.DataFrame(y_hat_dtree_weekly).to_csv(str(prefix_file)+str(i+1)+\"_pred.csv\",header=[\"pred_income\"], index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab 03 results:\n",
    "# adult_2021_cw_1.csv accuracy_score: 0.8293736501079914 \n",
    "# adult_2021_cw_2.csv accuracy_score: 0.8503253796095445 \n",
    "# adult_2021_cw_3.csv accuracy_score: 0.8427807486631016 \n",
    "# adult_2021_cw_4.csv accuracy_score: 0.8307860262008734 \n",
    "# adult_2021_cw_5.csv accuracy_score: 0.8507462686567164 \n",
    "# adult_2021_cw_6.csv accuracy_score: 0.854978354978355 \n",
    "# adult_2021_cw_7.csv accuracy_score: 0.8545454545454545 \n",
    "# adult_2021_cw_8.csv accuracy_score: 0.8514531754574811 \n",
    "# adult_2021_cw_9.csv accuracy_score: 0.8296943231441049 \n",
    "# adult_2021_cw_10.csv accuracy_score: 0.8574537540805223 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n",
      "\n",
      "Time elapsed 255.32171940803528 \n",
      "\n",
      "*******************************************************\n",
      "\n",
      "Evaluate Decision Tree Classifier Pipeline on new data\n",
      "******************************************************* \n",
      "\n",
      "Best hyperparameters {'classifier': DecisionTreeClassifier(max_depth=9, max_features=27, min_samples_split=5,\n",
      "                       random_state=1), 'classifier__criterion': 'gini', 'classifier__max_depth': 9, 'classifier__max_features': 27, 'classifier__min_samples_split': 5}\n",
      "Train accuracy_score 0.8541174520286792\n",
      "Test accuracy_score 0.8508204873197415\n",
      "Evaluation accuracy_score 0.846879150066401 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run \"main_romain_claret_and_sylvain_robert-nicoud_lab4.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult_2021_cw_1_pred.csv accuracy_score: 0.844103930712858 \n",
      "\n",
      "adult_2021_cw_2_pred.csv accuracy_score: 0.851063829787234 \n",
      "\n",
      "adult_2021_cw_3_pred.csv accuracy_score: 0.8498338870431894 \n",
      "\n",
      "adult_2021_cw_4_pred.csv accuracy_score: 0.8384512683578104 \n",
      "\n",
      "adult_2021_cw_5_pred.csv accuracy_score: 0.8373015873015873 \n",
      "\n",
      "adult_2021_cw_6_pred.csv accuracy_score: 0.8429530201342282 \n",
      "\n",
      "adult_2021_cw_7_pred.csv accuracy_score: 0.8551859099804305 \n",
      "\n",
      "adult_2021_cw_8_pred.csv accuracy_score: 0.8531746031746031 \n",
      "\n",
      "adult_2021_cw_9_pred.csv accuracy_score: 0.8411214953271028 \n",
      "\n",
      "adult_2021_cw_10_pred.csv accuracy_score: 0.8557114228456913 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run \"predict_income_romain_claret_and_sylvain_robert-nicoud_lab4.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
